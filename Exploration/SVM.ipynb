{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data\n",
    "\n",
    "I'm using the lemmatized data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Data/Train_Data/pre_processed/train_data_lemmatized.csv\")\n",
    "valid = pd.read_csv(\"../Data/Validation_Data/pre_processed/validation_data_lemmatized.csv\")\n",
    "test = pd.read_csv(\"../Data/Test_Data/pre_processed/test_data_lemmatized.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../Data/Train_Data/UnProcessed/train_data_unprocessed.csv\")\n",
    "valid = pd.read_csv(\"../Data/Validation_Data/UnProcessed/validation_data_filtered.csv\")\n",
    "test = pd.read_csv(\"../Data/Test_Data/un_processed/test_data_filtered.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorize the Data\n",
    "\n",
    "I'm using the string split() method as my tokenizer.\n",
    "\n",
    "Bag-of-Unigrams, bigrams, and trigrams as features.\n",
    "\n",
    "Might modify code to optimize MAX_NGRAM hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/feature_extraction/text.py:525: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "MAX_NGRAM = 3\n",
    "\n",
    "la_cv = CountVectorizer(lowercase=False, tokenizer=lambda s : s.split(), ngram_range=(1, MAX_NGRAM))\n",
    "en_cv = CountVectorizer(lowercase=False, tokenizer=lambda s : s.split())\n",
    "\n",
    "la_train = la_cv.fit_transform(train[\"la\"])\n",
    "la_valid = la_cv.transform(valid[\"la\"])\n",
    "la_test = la_cv.transform(test[\"la\"])\n",
    "en_train = en_cv.fit_transform(train[\"en\"])\n",
    "en_valid = en_cv.transform(valid[\"en\"])\n",
    "en_test = en_cv.transform(test[\"en\"])\n",
    "\n",
    "file_train = train[\"file\"]\n",
    "file_valid = valid[\"file\"]\n",
    "file_test = test[\"file\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the Models\n",
    "\n",
    "Currently I am not using the validation at all.\n",
    "\n",
    "I want to eventually use it to optimize MAX_NGRAM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latin accuracy: 0.9033149171270718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/sklearn/svm/_classes.py:32: FutureWarning: The default value of `dual` will change from `True` to `'auto'` in 1.5. Set the value of `dual` explicitly to suppress the warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English accuracy: 0.8867403314917127\n"
     ]
    }
   ],
   "source": [
    "la_svm = LinearSVC()\n",
    "la_svm.fit(la_train, file_train)\n",
    "la_predictions = la_svm.predict(la_test)\n",
    "print(\"Latin accuracy:\", np.mean(la_predictions == file_test))\n",
    "\n",
    "en_svm = LinearSVC()\n",
    "en_svm.fit(en_train, file_train)\n",
    "en_predictions = en_svm.predict(en_test)\n",
    "print(\"English accuracy:\", np.mean(en_predictions == file_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
